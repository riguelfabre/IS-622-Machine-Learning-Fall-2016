{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import random\n",
    "import requests\n",
    "import cv2\n",
    "import operator\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from __future__ import print_function\n",
    "from scipy import ndimage\n",
    "\n",
    "\n",
    "# Import library to display results\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import pyplot\n",
    "%matplotlib inline \n",
    "# Display images within Jupyter\n",
    "\n",
    "\n",
    "from keras.utils import np_utils\n",
    "import keras.callbacks as cb\n",
    "from keras.models import Sequential\n",
    "from keras.layers.convolutional import Convolution2D, MaxPooling2D\n",
    "from keras.layers.core import Dense, Dropout, Activation, Flatten\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.datasets import mnist\n",
    "from keras.datasets import cnn_mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "emotions = pd.read_csv('500_images.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "filenames = emotions[\"Image Name\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_set = filenames[150: ]\n",
    "test_set = filenames[350: ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#1-Scaling\n",
    "\n",
    "num = 1\n",
    "for name in filenames:\n",
    "    pathToFileInDisk = name\n",
    "    img = cv2.imread(name)\n",
    "    height, width = img.shape[:2]\n",
    "    res = cv2.resize(img,(10*width, 10*height), interpolation = cv2.INTER_CUBIC)\n",
    "    cv2.imwrite('Scale'+str(num)+'.jpg', res)\n",
    "    num=num+1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#2-Translation\n",
    "\n",
    "num = 1\n",
    "for name in filenames:\n",
    "    pathToFileInDisk = name\n",
    "    img = cv2.imread(name)\n",
    "    rows,cols = img.shape[:2]\n",
    "    M = np.float32([[1,0,100],[0,1,50]])\n",
    "    dst = cv2.warpAffine(img,M,(cols,rows))\n",
    "    cv2.imwrite('Translation'+str(num)+'.jpg', dst)\n",
    "    num=num+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#3-Rotation\n",
    "\n",
    "num = 1\n",
    "for name in filenames:\n",
    "    pathToFileInDisk = name\n",
    "    img = cv2.imread(name)\n",
    "    rows,cols = img.shape[:2]\n",
    "    M = cv2.getRotationMatrix2D((cols/2,rows/2),90,1)\n",
    "    dst = cv2.warpAffine(img,M,(cols,rows))\n",
    "    cv2.imwrite('Rotation'+str(num)+'.jpg', dst)\n",
    "    num=num+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#4-Affine Transformation\n",
    "\n",
    "num = 1\n",
    "for name in filenames:\n",
    "    pathToFileInDisk = name\n",
    "    img = cv2.imread(name)\n",
    "    rows,cols = img.shape[:2]\n",
    "    pts1 = np.float32([[50,50],[200,50],[50,200]])\n",
    "    pts2 = np.float32([[10,100],[200,50],[100,250]])\n",
    "    M = cv2.getAffineTransform(pts1,pts2)\n",
    "    dst = cv2.warpAffine(img,M,(cols,rows))\n",
    "    cv2.imwrite('Affine'+str(num)+'.jpg', dst)\n",
    "    num=num+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#5-Perspective Transformation\n",
    "\n",
    "num = 1\n",
    "for name in filenames:\n",
    "    pathToFileInDisk = name\n",
    "    img = cv2.imread(name)\n",
    "    rows,cols = img.shape[:2]\n",
    "    pts1 = np.float32([[56,65],[368,52],[28,387],[389,390]])\n",
    "    pts2 = np.float32([[0,0],[300,0],[0,300],[300,300]])\n",
    "    M = cv2.getPerspectiveTransform(pts1,pts2)\n",
    "    dst = cv2.warpPerspective(img,M,(300,300))\n",
    "    cv2.imwrite('Perspective'+str(num)+'.jpg', dst)\n",
    "    num=num+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#6-Gaussian Filtering\n",
    "\n",
    "num = 1\n",
    "for name in filenames:\n",
    "    pathToFileInDisk = name\n",
    "    img = cv2.imread(name)\n",
    "    Gblur = cv2.GaussianBlur(img,(5,5),3)\n",
    "    cv2.imwrite('Gblur'+str(num)+'.jpg', Gblur)\n",
    "    num=num+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#7-Erosion\n",
    "\n",
    "num = 1\n",
    "for name in filenames:\n",
    "    pathToFileInDisk = name\n",
    "    img = cv2.imread(name,0)\n",
    "    kernel = np.ones((10,10),np.uint8)\n",
    "    erosion = cv2.erode(img,kernel,iterations = 1)\n",
    "    cv2.imwrite('erosion'+str(num)+'.jpg', erosion)\n",
    "    num=num+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#8-Dilation\n",
    "\n",
    "num = 1\n",
    "for name in filenames:\n",
    "    pathToFileInDisk = name\n",
    "    img = cv2.imread(name,0)\n",
    "    kernel = np.ones((5,5),np.uint8)\n",
    "    dilation = cv2.dilate(img,kernel,iterations = 1)\n",
    "    cv2.imwrite('Dilation'+str(num)+'.jpg', dilation)\n",
    "    num=num+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#9-Gradient\n",
    "\n",
    "num = 1\n",
    "for name in filenames:\n",
    "    pathToFileInDisk = name\n",
    "    img = cv2.imread(name,0)\n",
    "    kernel = np.ones((5,5),np.uint8)\n",
    "    gradient = cv2.morphologyEx(img, cv2.MORPH_GRADIENT, kernel)\n",
    "    cv2.imwrite('Gradient'+str(num)+'.jpg', gradient)\n",
    "    num=num+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#10-Sobel Derivatives\n",
    "\n",
    "\n",
    "num = 1\n",
    "for name in filenames:\n",
    "    pathToFileInDisk = name\n",
    "    img = cv2.imread(name,0)\n",
    "    sobelx = cv2.Sobel(img,cv2.CV_64F,1,0,ksize=5)\n",
    "    cv2.imwrite('Sobelx'+str(num)+'.jpg', sobelx)\n",
    "    num=num+1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#11-Median Blur\n",
    "num = 1\n",
    "for name in train_set:\n",
    "    pathToFileInDisk = name\n",
    "    img = cv2.imread(name,0)\n",
    "    median = cv2.medianBlur(img,1)\n",
    "    cv2.imwrite('Median'+str(num)+'.jpg', median)\n",
    "    num=num+1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#12-Bilateral filtering\n",
    "\n",
    "num = 1\n",
    "for name in train_set:\n",
    "    pathToFileInDisk = name\n",
    "    img = cv2.imread(name,0)\n",
    "    bl = cv2.bilateralFilter(img,9,75,75)\n",
    "    cv2.imwrite('Bilateral'+str(num)+'.jpg', bl)\n",
    "    num=num+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#13-noisy Filtering\n",
    "\n",
    "num = 1\n",
    "for name in train_set:\n",
    "    pathToFileInDisk = name\n",
    "    img = cv2.imread(name,0)\n",
    "    img[230:290, 220:320]\n",
    "    noisy = img + 0.4 * img.std() * np.random.random(img.shape)\n",
    "    cv2.imwrite('Noisy'+str(num)+'.jpg', noisy)\n",
    "    num=num+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#14-Flipped\n",
    "\n",
    "num = 1\n",
    "for name in train_set:\n",
    "    pathToFileInDisk = name\n",
    "    img = cv2.imread(name,0)\n",
    "    flip = np.flipud(img)\n",
    "    cv2.imwrite('flip'+str(num)+'.jpg', flip)\n",
    "    num=num+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#15-Sharpened\n",
    "num = 1\n",
    "for name in train_set:\n",
    "    pathToFileInDisk = name\n",
    "    img = cv2.imread(name,0)\n",
    "    blurred_img = ndimage.gaussian_filter(img, 3)\n",
    "    filter_blurred_img = ndimage.gaussian_filter(blurred_img, 1)\n",
    "    alpha = 20\n",
    "    sharpened = blurred_img + alpha * (blurred_img - filter_blurred_img)\n",
    "    cv2.imwrite('Sharp'+str(num)+'.jpg', sharpened)\n",
    "    num=num+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#16-Uniform filtering\n",
    "\n",
    "\n",
    "num = 1\n",
    "for name in train_set:\n",
    "    pathToFileInDisk = name\n",
    "    img = cv2.imread(name,0)\n",
    "    uni = ndimage.uniform_filter(img, size=22)\n",
    "    cv2.imwrite('uni'+str(num)+'.jpg', uni)\n",
    "    num=num+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class LossHistory(cb.Callback):\n",
    "    def on_train_begin(self, logs={}):\n",
    "        self.losses = []\n",
    "\n",
    "\n",
    "\n",
    "def on_batch_end(self, batch, logs={}):\n",
    "    batch_loss = logs.get('loss')\n",
    "    self.losses.append(batch_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    print 'Loading data...'\n",
    "    (X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "\n",
    "\n",
    "    X_train = X_train.astype('float32')\n",
    "    X_test = X_test.astype('float32')\n",
    "\n",
    "\n",
    "    X_train /= 255\n",
    "    X_test /= 255\n",
    "\n",
    "\n",
    "    y_train = np_utils.to_categorical(y_train, 10)\n",
    "    y_test = np_utils.to_categorical(y_test, 10)\n",
    "\n",
    "\n",
    "    X_train = np.reshape(X_train, (60000, 1, 28,28))\n",
    "    X_test = np.reshape(X_test, (10000, 1, 28,28))\n",
    "\n",
    "\n",
    "    print 'Data loaded.'\n",
    "    return [X_train, X_test, y_train, y_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def init_model():\n",
    "    start_time = time.time()\n",
    "    print 'Compiling Model ... '\n",
    "    model = Sequential()\n",
    "    model.add(Convolution2D(64, 3,3, border_mode='same', input_shape=(1,28,28)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "    model.add(Dropout(.25))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(10))\n",
    "    model.add(Activation('softmax'))\n",
    "\n",
    "    rms = RMSprop()\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=rms,\n",
    "    metrics=['accuracy'])\n",
    "\n",
    "    print 'Model compiled in {0} seconds'.format(time.time() - start_time)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def init_model_1():\n",
    "    start_time = time.time()\n",
    "    print 'Compiling Model ... '\n",
    "    model = Sequential()\n",
    "    model.add(Convolution2D(64, 3,3, border_mode='valid',input_shape=(1,28,28)))\n",
    "    model.add(Activation('relu'))\n",
    "\n",
    "    model.add(Convolution2D(64, 3,3, border_mode='valid',input_shape=(1,28,28)))\n",
    "    model.add(Activation('relu'))\n",
    "\n",
    "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "    model.add(Dropout(.25))\n",
    "\n",
    "    model.add(Flatten())\n",
    "\n",
    "    model.add(Dense(128))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(.5))\n",
    "\n",
    "    model.add(Dense(10))\n",
    "    model.add(Activation('softmax'))\n",
    "\n",
    "    rms = RMSprop()\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=rms,\n",
    "    metrics=['accuracy'])\n",
    "\n",
    "    print 'Model compiled in {0} seconds'.format(time.time() - start_time)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def run_network(data=None, model=None, epochs=20, batch=256):\n",
    "    try:\n",
    "        start_time = time.time()\n",
    "        if data is None:\n",
    "            X_train, X_test, y_train, y_test = load_data()\n",
    "        else:\n",
    "            X_train, X_test, y_train, y_test = data\n",
    "\n",
    "        if model is None:\n",
    "            model = init_model()\n",
    "\n",
    "        history = LossHistory()\n",
    "        print 'Training model...'\n",
    "\n",
    "        model.fit(X_train, y_train, nb_epoch=epochs, batch_size=batch,\n",
    "\n",
    "                  callbacks=[history],\n",
    "\n",
    "                  validation_data=(X_test, y_test), verbose=2)\n",
    "\n",
    "\n",
    "\n",
    "        print \"Training duration : {0}\".format(time.time() - start_time)\n",
    "\n",
    "        score = model.evaluate(X_test, y_test, batch_size=16)\n",
    "\n",
    "\n",
    "\n",
    "        print \"Network's test score [loss, accuracy]: {0}\".format(score)\n",
    "\n",
    "        return model, history.losses\n",
    "\n",
    "    except KeyboardInterrupt:\n",
    "\n",
    "        print ' KeyboardInterrupt'\n",
    "\n",
    "        return model, history.losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predict(model, images):\n",
    "\n",
    "  \"\"\"\n",
    "\n",
    "  Takes an array of images. Obviously dimensions must match training set.\n",
    "\n",
    "  \"\"\"\n",
    "\n",
    "  return model.predict_classes(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def display_classes(png, images, classes, ncol=4):\n",
    "    \"\"\"\n",
    "    Draw a number of images and their predictions\n",
    "\n",
    "\n",
    "    Example:\n",
    "    images = data[1][:12]\n",
    "    classes = model.predict_classes('classes.png', images)\n",
    "    \"\"\"\n",
    "\n",
    "    fig = plt.figure()\n",
    "    nrow = len(images) / ncol\n",
    "    if len(images) % ncol > 0: nrow = nrow + 1\n",
    "\n",
    "\n",
    "\n",
    "def draw(i):\n",
    "    plt.subplot(nrow,ncol,i)\n",
    "    plt.imshow(images[i].reshape(28,28), cmap='gray', interpolation='none')\n",
    "    plt.title('Predicted: %s' % classes[i])\n",
    "    [ draw(i) for i in range(0,len(images)) ]\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(png)\n",
    "\n",
    "\n",
    "\n",
    "def plot_losses(png, losses):\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111)\n",
    "    ax.plot(losses)\n",
    "    ax.set_title('Loss per batch')\n",
    "    plt.savefig(png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = .load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = .init_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "(model, loss) = .run_network(data, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cnn_mnist.plot_losses('loss.png', loss)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
